<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Paul W" />

<meta name="date" content="2015-07-25" />

<title>The right way and the wrong way to exercise</title>

<script src="practicalML_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="practicalML_files/bootstrap-3.3.1/css/bootstrap.min.css" rel="stylesheet" />
<script src="practicalML_files/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="practicalML_files/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="practicalML_files/bootstrap-3.3.1/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="practicalML_files/highlight/default.css"
      type="text/css" />
<script src="practicalML_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">The right way and the wrong way to exercise</h1>
<h4 class="author"><em>Paul W</em></h4>
<h4 class="date"><em>25 July 2015</em></h4>
</div>


<p>Six participants were asked to perform a series of simple exercises (lifting a dumbbell) in five different ways, labelled A-E. One of these techniques was the “correct” way of lifting, the remaining four ways were representative of common mistakes. Sensors (gyroscope, accelerometer, magnetometer) in the participants’ dumbbell, glove, forearm and belt recorded various quantities (roll, pitch, yaw, amplitude, acceleration, kurtosis, skewness) during each set of manouevres. Given these data, is it possible to train a model to recognise which movements are correct, and which are incorrect?</p>
<p>A training dataset was provided, containing 19,622 observations of 124 features. Many of these features showed little or no variance over the course of the test, and so were removed from the dataset. Similarly many features were not recorded (NAs), and were also removed.</p>
<pre class="r"><code>setwd(&#39;.&#39;)
library(caret); library(doParallel); library(randomForest)
# Read the provided training and test sets
training &lt;- read.csv(&#39;pml-training.csv&#39;,na.strings=c(&quot;&quot;,&quot;NA&quot;,&quot;NaN&quot;,&quot;#DIV/0!&quot;),stringsAsFactors = FALSE)
testing &lt;- read.csv(&#39;pml-testing.csv&#39;,na.strings=c(&quot;&quot;,&quot;NA&quot;,&quot;NaN&quot;,&quot;#DIV/0!&quot;),stringsAsFactors = FALSE)
# Remove variables with near-zero variance, which are unlikely to contribute much to the model
nzv&lt;-nearZeroVar(training)
training&lt;-training[, -nzv]
testing&lt;-testing[, -nzv]
# Strip out the unmeasured variables, keeping the good data
goodTrain &lt;- training[,c(7:10,33:45,47:55,66:68,81,92:103,113,115:124)]
goodTest &lt;- testing[,c(7:10,33:45,47:55,66:68,81,92:103,113,115:124)]
# &#39;classe&#39; is the labeling of the movements (the outcome we are trying to predict). Make this a factor with levels A, B, C, D, E.
goodTrain$classe &lt;- as.factor(goodTrain$classe)</code></pre>
<p>Since the test dataset does not contain any classifications, the training set was partitioned in order to provide a validation set on which to test the model.</p>
<pre class="r"><code>dpIndex &lt;- createDataPartition(y=goodTrain$classe, p=0.70, list=FALSE )
trainPart &lt;- goodTrain[dpIndex,]
validPart &lt;- goodTrain[-dpIndex,]</code></pre>
<p>Exploring the data a little, it seemed clear that since many measurements are clustered when segmented by <code>classe</code>, some kind of hierarchical tree method (e.g., Random Forest) would be appropriate.</p>
<pre class="r"><code>names(trainPart)</code></pre>
<pre><code>##  [1] &quot;roll_belt&quot;            &quot;pitch_belt&quot;           &quot;yaw_belt&quot;            
##  [4] &quot;total_accel_belt&quot;     &quot;gyros_belt_x&quot;         &quot;gyros_belt_y&quot;        
##  [7] &quot;gyros_belt_z&quot;         &quot;accel_belt_x&quot;         &quot;accel_belt_y&quot;        
## [10] &quot;accel_belt_z&quot;         &quot;magnet_belt_x&quot;        &quot;magnet_belt_y&quot;       
## [13] &quot;magnet_belt_z&quot;        &quot;roll_arm&quot;             &quot;pitch_arm&quot;           
## [16] &quot;yaw_arm&quot;              &quot;total_accel_arm&quot;      &quot;gyros_arm_x&quot;         
## [19] &quot;gyros_arm_y&quot;          &quot;gyros_arm_z&quot;          &quot;accel_arm_x&quot;         
## [22] &quot;accel_arm_y&quot;          &quot;accel_arm_z&quot;          &quot;magnet_arm_x&quot;        
## [25] &quot;magnet_arm_y&quot;         &quot;magnet_arm_z&quot;         &quot;roll_dumbbell&quot;       
## [28] &quot;pitch_dumbbell&quot;       &quot;yaw_dumbbell&quot;         &quot;total_accel_dumbbell&quot;
## [31] &quot;gyros_dumbbell_x&quot;     &quot;gyros_dumbbell_y&quot;     &quot;gyros_dumbbell_z&quot;    
## [34] &quot;accel_dumbbell_x&quot;     &quot;accel_dumbbell_y&quot;     &quot;accel_dumbbell_z&quot;    
## [37] &quot;magnet_dumbbell_x&quot;    &quot;magnet_dumbbell_y&quot;    &quot;magnet_dumbbell_z&quot;   
## [40] &quot;roll_forearm&quot;         &quot;pitch_forearm&quot;        &quot;yaw_forearm&quot;         
## [43] &quot;total_accel_forearm&quot;  &quot;gyros_forearm_x&quot;      &quot;gyros_forearm_y&quot;     
## [46] &quot;gyros_forearm_z&quot;      &quot;accel_forearm_x&quot;      &quot;accel_forearm_y&quot;     
## [49] &quot;accel_forearm_z&quot;      &quot;magnet_forearm_x&quot;     &quot;magnet_forearm_y&quot;    
## [52] &quot;magnet_forearm_z&quot;     &quot;classe&quot;</code></pre>
<pre class="r"><code>featurePlot(x=trainPart[,c(&quot;roll_dumbbell&quot;,&quot;pitch_dumbbell&quot;,&quot;yaw_dumbbell&quot;,&quot;total_accel_dumbbell&quot;)],y=trainPart$classe,plot=&quot;pairs&quot;)</code></pre>
<p><img src="practicalML_files/figure-html/unnamed-chunk-3-1.png" title="" alt="" width="672" /></p>
<p>Using a Random Forest classification model, we can fit <code>classe</code> as a function of all the other variables. Performing the fitting in parallel helps to speed up the process. Fitting with 200+ trees, multiple times, produces an accuracy of 99+%:</p>
<pre class="r"><code>registerDoParallel(2, cores=2)

rf &lt;- foreach(ntree=rep(300, 3), .combine=randomForest::combine, .packages=&#39;randomForest&#39;) %dopar% {
  randomForest(trainPart[,c(1:ncol(trainPart)-1)], trainPart$classe, ntree=ntree) 
}
predForValid &lt;- predict(rf, newdata=validPart)
confusionMatrix(predForValid,validPart$classe)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1673    4    0    0    0
##          B    0 1134    7    0    0
##          C    0    1 1017   15    1
##          D    0    0    2  949    3
##          E    1    0    0    0 1078
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9942         
##                  95% CI : (0.9919, 0.996)
##     No Information Rate : 0.2845         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9927         
##  Mcnemar&#39;s Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9994   0.9956   0.9912   0.9844   0.9963
## Specificity            0.9991   0.9985   0.9965   0.9990   0.9998
## Pos Pred Value         0.9976   0.9939   0.9836   0.9948   0.9991
## Neg Pred Value         0.9998   0.9989   0.9981   0.9970   0.9992
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2843   0.1927   0.1728   0.1613   0.1832
## Detection Prevalence   0.2850   0.1939   0.1757   0.1621   0.1833
## Balanced Accuracy      0.9992   0.9971   0.9939   0.9917   0.9980</code></pre>
<p>The confusion matrix tells us that the out-of-sample error rate is 31/6885, or 0.5%. Having fitted a model, we can identify the most significant variables:</p>
<pre class="r"><code>varImpForModel &lt;- varImp(rf)
par(mar=c(5,9,4,2)+0.1)
barplot(varImpForModel[order(varImpForModel[1],decreasing = TRUE)[20:1],1], main = &quot;Variable importance&quot;,horiz=TRUE,names.arg=rownames(varImpForModel)[order(varImpForModel[1],decreasing = TRUE)[20:1]],las=1)</code></pre>
<p><img src="practicalML_files/figure-html/unnamed-chunk-5-1.png" title="" alt="" width="672" /></p>
<p>We can now apply the model to the testing data that was witheld until now:</p>
<pre class="r"><code>predForTest &lt;- predict(rf, newdata=goodTest)
predForTest</code></pre>
<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E</code></pre>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
